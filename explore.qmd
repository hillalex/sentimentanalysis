---
title: "How do people talk about pregnancy?"
format:
  html:
    code-fold: false
jupyter: python3
---

## Exploring the data

To get a first idea of the distribution of sentiment scores, here are the density plots for
the control sample and the tweets about pregnancy:

```{python}
import pandas as pd
import glob
import os
import matplotlib.pyplot as plt

all_files = glob.glob(os.path.join("data", "*/scoredalltweets.csv"))
df = pd.concat((pd.read_csv(f) for f in all_files))

all_files = glob.glob(os.path.join("data", "*/scoredpregnancytweets.csv"))
df_preg = pd.concat((pd.read_csv(f) for f in all_files))
```

```{python}
fig, axes = plt.subplots(nrows=1,ncols=2)
df[["sentiment"]].plot.density(ax = axes[0])
df_preg[["sentiment"]].plot.density(ax = axes[1]);
```

There seem to be a disproportionate number of neutrally coded tweets in the control group.
What do these look like?

```{python}
tab = df[df.sentiment == 0].sample(n=10).text
from IPython.display import Markdown
from tabulate import tabulate
Markdown(tabulate(list(map(lambda x:[x.replace("\n", " ")], tab))))
```

It feels like these are more unclassifiable than classifiably neutral.

The positive skew of all tweets and more symmetric distribution of the keyword tweets is even clearer if looking at the
boxplots, but I wonder how much this is just influenced by all these zero scores tweets.

```{python}
fig, axes = plt.subplots(nrows=1,ncols=2)
df[["sentiment"]].boxplot(ax = axes[0])
df_preg[["sentiment"]].boxplot(ax = axes[1]);
```

If we leave them out, we get:

```{python}
df = df[df.sentiment != 0]
df_preg = df_preg[df_preg.sentiment != 0]
fig, axes = plt.subplots(nrows=1,ncols=2)
df[["sentiment"]].boxplot(ax = axes[0])
df_preg[["sentiment"]].boxplot(ax = axes[1]);
```

These distributions look very similar.

Ok, so what do the most negative and positive tweets about pregnancy look like?
Here are some of the most negative tweets:

```{python}
sorted = df_preg.sort_values(by="sentiment")
worst = sorted.head(5).text
from IPython.display import Markdown
from tabulate import tabulate
Markdown(tabulate(list(map(lambda x:[x.replace("\n", " ")], worst))))
```

A lot of these seem to be about political issues like abortion or trans rights.
And some of the most positive:

```{python}
best = sorted.tail(5).text
from IPython.display import Markdown
from tabulate import tabulate
Markdown(tabulate(list(map(lambda x:[x.replace("\n", " ")], best))))
```

These aren't looking very relevant either, unfortunately. None seem to be actually be
about the experience of pregnancy. A lot are just about celebrity gossip.

Does removing mentions of Rhianna and Beyonce, as well as abortion and trans people,
 from the data change the distribution at all?

```{python}
df_preg_1 = df_preg[~df_preg.text.str.contains("rhi|rih|riri|bey|trans|abort", case=False, regex=True)]
fig, axes = plt.subplots(nrows=1,ncols=2)
df_preg[["sentiment"]].boxplot(ax = axes[0])
df_preg_1[["sentiment"]].boxplot(ax = axes[1]);
```

```{python}
sorted = df_preg_1.sort_values(by="sentiment")
worst = sorted.head(10).text
from IPython.display import Markdown
from tabulate import tabulate
Markdown(tabulate(list(map(lambda x:[x.replace("\n", " ")], worst))))
```

These do seem a lot more relevant, and correctly scored as negative.

```{python}
sorted = df_preg_1.sort_values(by="sentiment")
best = sorted.tail(10).text
from IPython.display import Markdown
from tabulate import tabulate
Markdown(tabulate(list(map(lambda x:[x.replace("\n", " ")], best))))
```

These seem relevant, although it does look like the scoring is off; at least 2 of the top 10 most positively
rated tweets are clearly expressing negative sentiments.

Comparing the improved set with the control set now:

```{python}
fig, axes = plt.subplots(nrows=1,ncols=2)
df_preg[["sentiment"]].boxplot(ax = axes[0])
df_preg_1[["sentiment"]].boxplot(ax = axes[1]);
```

Looks like chat about pregnancy on Twitter is remarkably balanced.
